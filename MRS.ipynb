{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efaf02ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n",
      "Training       28709\n",
      "PublicTest      3589\n",
      "PrivateTest     3589\n",
      "Name: Usage, dtype: int64\n",
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
      "Epoch 1/10\n",
      "449/449 [==============================] - 141s 313ms/step - loss: 1.7181 - accuracy: 0.3188 - val_loss: 1.6255 - val_accuracy: 0.3876\n",
      "Epoch 2/10\n",
      "449/449 [==============================] - 147s 327ms/step - loss: 1.4839 - accuracy: 0.4204 - val_loss: 1.3843 - val_accuracy: 0.4631\n",
      "Epoch 3/10\n",
      "449/449 [==============================] - 135s 300ms/step - loss: 1.3633 - accuracy: 0.4736 - val_loss: 1.3878 - val_accuracy: 0.4748\n",
      "Epoch 4/10\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 1.2824 - accuracy: 0.5038 - val_loss: 1.2562 - val_accuracy: 0.5194\n",
      "Epoch 5/10\n",
      "449/449 [==============================] - 136s 303ms/step - loss: 1.2221 - accuracy: 0.5309 - val_loss: 1.2290 - val_accuracy: 0.5391\n",
      "Epoch 6/10\n",
      "449/449 [==============================] - 134s 298ms/step - loss: 1.1711 - accuracy: 0.5518 - val_loss: 1.1986 - val_accuracy: 0.5483\n",
      "Epoch 7/10\n",
      "449/449 [==============================] - 134s 298ms/step - loss: 1.1234 - accuracy: 0.5699 - val_loss: 1.1397 - val_accuracy: 0.5715\n",
      "Epoch 8/10\n",
      "449/449 [==============================] - 133s 296ms/step - loss: 1.0820 - accuracy: 0.5869 - val_loss: 1.1457 - val_accuracy: 0.5840\n",
      "Epoch 9/10\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 1.0366 - accuracy: 0.6047 - val_loss: 1.1501 - val_accuracy: 0.5659\n",
      "Epoch 10/10\n",
      "449/449 [==============================] - 133s 297ms/step - loss: 1.0052 - accuracy: 0.6220 - val_loss: 1.1531 - val_accuracy: 0.5743\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#size of your terminal window\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df=pd.read_csv('fer2013.csv')\n",
    "print(df.info())\n",
    "print(df[\"Usage\"].value_counts())\n",
    "\n",
    "print(df.head())\n",
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            X_train.append(np.array(val,'float32'))\n",
    "            train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            X_test.append(np.array(val,'float32'))\n",
    "            test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n",
    "\n",
    "\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "#cannot produce\n",
    "#normalizing data between o and 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "\n",
    "# print(f\"shape:{X_train.shape}\")\n",
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49130e94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "You are angry !!!! please calm down:) ,I will play song for you :ERA- King.mp3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os,random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "#from tensorflow.keras.utils import load_img, img_to_array\n",
    "import keras.utils as image\n",
    "#from keras.preprocessing import image\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#load model\n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "#load weights\n",
    "model.load_weights('fer.h5')\n",
    "\n",
    "size = 4\n",
    "# We load the xml file\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "global text\n",
    "cap = cv2.VideoCapture(0)  # Using default WebCam connected to the PC.\n",
    "now = time.time()###For calculate seconds of video\n",
    "future = now + 10  ####here is second of time which taken by emotion recognition system ,you can change it\n",
    "while True:\n",
    "    ret,im=cap.read()# captures frame and returns boolean value and captured image\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_detected = classifier.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        #find max indexed array\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        emotions = ('Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral')\n",
    "        text = emotions[max_index]\n",
    "        font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "\n",
    "        if text == 'Angry':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0, 25, 255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0, 25,255), 2)\n",
    "\n",
    "        if text == 'Disgust':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0,260,0), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0,260,0), 2)\n",
    "\n",
    "        if text == 'Fear':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0, 255, 255), 2)\n",
    "\n",
    "        if text == 'Sad':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0,191,255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0,191,255), 2)\n",
    "            \n",
    "        if text == 'Happy':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0,191,255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0,191,255), 2)\n",
    "            \n",
    "        if text == 'Surprise':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0,191,255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0,191,255), 2)\n",
    "            \n",
    "        if text == 'Neutral':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0,191,255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0,191,255), 2)\n",
    "\n",
    "    # Show the image/\n",
    "    cv2.imshow('Music player with Emotion recognition', im)\n",
    "    key = cv2.waitKey(5)& 0xff\n",
    "    if time.time() > future:##after 20second music will play\n",
    "        try:\n",
    "            cv2.destroyAllWindows()\n",
    "            mp = 'C:/Program Files (x86)/Windows Media Player/wmplayer.exe'\n",
    "            if text == 'Happy':\n",
    "                randomfile = random.choice(os.listdir(\"Minor project/Happy\"))\n",
    "                print('You are smiling :) ,I am playing a special song for you: ' + randomfile)\n",
    "                file = (r'C:/Users/mishr/MINOR PROJECT/Happy//'+'//'+randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "\n",
    "            if text == 'Angry':\n",
    "                randomfile = random.choice(os.listdir(\"Minor project/Angry/\"))\n",
    "                print('You are angry !!!! please calm down:) ,I will play song for you :' + randomfile)\n",
    "                file = (r'C:/Users/mishr/MINOR PROJECT/Angry//'+'//'+randomfile)\n",
    "                subprocess.call([mp, randomfile])\n",
    "\n",
    "            if text == 'Fear':\n",
    "                randomfile = random.choice(os.listdir(\"Minor project/Fear/\"))\n",
    "                print('You have fear of something ,I am playing a song for you: ' + randomfile)\n",
    "                file = (r'C:/Users/mishr/MINOR PROJECT/Fear//'+'//'+randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "\n",
    "            if text == 'Sad':\n",
    "                randomfile = random.choice(os.listdir(\"Minor project/Sad/\"))\n",
    "                print('You are sad,dont worry:) ,I am playing a song for you: ' + randomfile)\n",
    "                file = (r'C:/Users/mishr/MINOR PROJECT/Sad//'+'//'+randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "                \n",
    "            if text == 'Surprise':\n",
    "                randomfile = random.choice(os.listdir(\"Minor project/Surprise/\"))\n",
    "                print('You are surprised, just calm down:) ,I am playing a song for you: ' + randomfile)\n",
    "                file = (r'C:/Users/mishr/MINOR PROJECT/Surprise//'+'//'+randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "                \n",
    "            if text == 'Disgust':\n",
    "                randomfile = random.choice(os.listdir(\"Minor project/Disgust/\"))\n",
    "                print('You are disgusted ,let me cool you down:) ,I am playing a song for you: ' + randomfile)\n",
    "                file = (r'C:/Users/mishr/MINOR PROJECT/Disgust//'+'//'+randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "                \n",
    "            if text == 'Neutral':\n",
    "                randomfile = random.choice(os.listdir(\"Minor project/Neutral/\"))\n",
    "                print('You seems to be normal:) ,I am playing a song for you: ' + randomfile)\n",
    "                file = (r'C:/Users/mishr/MINOR PROJECT/Neutral//'+'//'+randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "            break\n",
    "\n",
    "        except :\n",
    "            print('Please stay focus in Camera frame atleast 15 seconds & run again this program:)')\n",
    "            break\n",
    "\n",
    "    if key == 27:  # The Esc key\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
